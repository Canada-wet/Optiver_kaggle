{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee1b3736",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-25T05:17:12.182821Z",
     "iopub.status.busy": "2022-01-25T05:17:12.177650Z",
     "iopub.status.idle": "2022-01-25T05:17:13.406546Z",
     "shell.execute_reply": "2022-01-25T05:17:13.405765Z",
     "shell.execute_reply.started": "2021-08-30T08:33:25.386079Z"
    },
    "papermill": {
     "duration": 1.261448,
     "end_time": "2022-01-25T05:17:13.406717",
     "exception": false,
     "start_time": "2022-01-25T05:17:12.145269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "\n",
    "\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "scores_folds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b38822b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T05:17:13.526040Z",
     "iopub.status.busy": "2022-01-25T05:17:13.490091Z",
     "iopub.status.idle": "2022-01-25T05:17:13.529288Z",
     "shell.execute_reply": "2022-01-25T05:17:13.528648Z",
     "shell.execute_reply.started": "2021-08-30T08:33:26.580455Z"
    },
    "papermill": {
     "duration": 0.099127,
     "end_time": "2022-01-25T05:17:13.529426",
     "exception": false,
     "start_time": "2022-01-25T05:17:13.430299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data directory\n",
    "data_dir = '../input/optiver-realized-volatility-prediction/'\n",
    "\n",
    "# Function to calculate first WAP\n",
    "def calc_wap1(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate second WAP\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap3(df):\n",
    "    wap = (df['bid_price1'] * df['bid_size1'] + df['ask_price1'] * df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap4(df):\n",
    "    wap = (df['bid_price2'] * df['bid_size2'] + df['ask_price2'] * df['ask_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate the log of the return\n",
    "# Remember that logb(x / y) = logb(x) - logb(y)\n",
    "def log_return(series):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "# Calculate the realized volatility\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "# Function to count unique elements of a series\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "# Function to read our base train and test set\n",
    "def read_train_test():\n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n",
    "    # Create a key to merge with book and trade data\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    print(f'Our training set has {train.shape[0]} rows')\n",
    "    return train, test\n",
    "\n",
    "# Function to preprocess book data (for each stock id)\n",
    "def book_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    # Calculate Wap\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    df['wap3'] = calc_wap3(df)\n",
    "    df['wap4'] = calc_wap4(df)\n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    df['log_return3'] = df.groupby(['time_id'])['wap3'].apply(log_return)\n",
    "    df['log_return4'] = df.groupby(['time_id'])['wap4'].apply(log_return)\n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    # Calculate spread\n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'wap1': [np.sum, np.std],\n",
    "        'wap2': [np.sum, np.std],\n",
    "        'wap3': [np.sum, np.std],\n",
    "        'wap4': [np.sum, np.std],\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "        'wap_balance': [np.sum, np.max],\n",
    "        'price_spread':[np.sum, np.max],\n",
    "        'price_spread2':[np.sum, np.max],\n",
    "        'bid_spread':[np.sum, np.max],\n",
    "        'ask_spread':[np.sum, np.max],\n",
    "        'total_volume':[np.sum, np.max],\n",
    "        'volume_imbalance':[np.sum, np.max],\n",
    "        \"bid_ask_spread\":[np.sum,  np.max],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "    }\n",
    "    \n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "\n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to preprocess trade data (for each stock id)\n",
    "def trade_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    df['amount']=df['price']*df['size']\n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, np.max, np.min],\n",
    "        'order_count':[np.sum,np.max],\n",
    "        'amount':[np.sum,np.max,np.min],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.sum],\n",
    "    }\n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "\n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        # new\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        \n",
    "        # vol vars\n",
    "        \n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to get group stats for the stock_id and time_id\n",
    "def get_time_stock(df):\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400', \n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200', \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_400', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_200']\n",
    "\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the time id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    return df\n",
    "    \n",
    "# Funtion to make preprocessing function in parallel (for each stock id)\n",
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    \n",
    "    # Parrallel for loop\n",
    "    def for_joblib(stock_id):\n",
    "        # Train\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        # Test\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "    \n",
    "        # Preprocess book and trade data and merge them\n",
    "        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n",
    "        \n",
    "        # Return the merge dataframe\n",
    "        return df_tmp\n",
    "    \n",
    "    # Use parallel api to call paralle for loop\n",
    "    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n",
    "    # Concatenate all the dataframes that return from Parallel\n",
    "    df = pd.concat(df, ignore_index = True)\n",
    "    return df\n",
    "\n",
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf2cf3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T05:17:13.581033Z",
     "iopub.status.busy": "2022-01-25T05:17:13.580164Z",
     "iopub.status.idle": "2022-01-25T05:49:16.423802Z",
     "shell.execute_reply": "2022-01-25T05:49:16.422809Z",
     "shell.execute_reply.started": "2021-08-30T08:33:26.649017Z"
    },
    "papermill": {
     "duration": 1922.872505,
     "end_time": "2022-01-25T05:49:16.424156",
     "exception": false,
     "start_time": "2022-01-25T05:17:13.551651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set has 428932 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed: 31.9min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Read train and test\n",
    "train, test = read_train_test()\n",
    "\n",
    "# Get unique stock ids \n",
    "train_stock_ids = train['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "train_ = preprocessor(train_stock_ids, is_train = True)\n",
    "train = train.merge(train_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get group stats of time_id and stock_id\n",
    "train = get_time_stock(train)\n",
    "test = get_time_stock(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "162cbbd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T05:49:16.490233Z",
     "iopub.status.busy": "2022-01-25T05:49:16.489190Z",
     "iopub.status.idle": "2022-01-25T05:49:16.504405Z",
     "shell.execute_reply": "2022-01-25T05:49:16.505046Z",
     "shell.execute_reply.started": "2021-08-30T09:16:34.754348Z"
    },
    "papermill": {
     "duration": 0.052399,
     "end_time": "2022-01-25T05:49:16.505230",
     "exception": false,
     "start_time": "2022-01-25T05:49:16.452831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace by order sum (tau)\n",
    "train['size_tau'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique'] )\n",
    "test['size_tau'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique'] )\n",
    "#train['size_tau_450'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_450'] )\n",
    "#test['size_tau_450'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_450'] )\n",
    "train['size_tau_400'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_400'] )\n",
    "test['size_tau_400'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_400'] )\n",
    "train['size_tau_300'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_300'] )\n",
    "test['size_tau_300'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_300'] )\n",
    "#train['size_tau_150'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_150'] )\n",
    "#test['size_tau_150'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_150'] )\n",
    "train['size_tau_200'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_200'] )\n",
    "test['size_tau_200'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_200'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab5271e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T05:49:16.564513Z",
     "iopub.status.busy": "2022-01-25T05:49:16.563188Z",
     "iopub.status.idle": "2022-01-25T05:49:16.581760Z",
     "shell.execute_reply": "2022-01-25T05:49:16.582283Z",
     "shell.execute_reply.started": "2021-08-30T09:16:34.790286Z"
    },
    "papermill": {
     "duration": 0.052363,
     "end_time": "2022-01-25T05:49:16.582508",
     "exception": false,
     "start_time": "2022-01-25T05:49:16.530145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['size_tau2'] = np.sqrt( 1/ train['trade_order_count_sum'] )\n",
    "test['size_tau2'] = np.sqrt( 1/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_450'] = np.sqrt( 0.25/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_450'] = np.sqrt( 0.25/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_400'] = np.sqrt( 0.33/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_400'] = np.sqrt( 0.33/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_300'] = np.sqrt( 0.5/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_300'] = np.sqrt( 0.5/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_150'] = np.sqrt( 0.75/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_150'] = np.sqrt( 0.75/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_200'] = np.sqrt( 0.66/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_200'] = np.sqrt( 0.66/ test['trade_order_count_sum'] )\n",
    "\n",
    "# delta tau\n",
    "train['size_tau2_d'] = train['size_tau2_400'] - train['size_tau2']\n",
    "test['size_tau2_d'] = test['size_tau2_400'] - test['size_tau2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392219c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T05:49:16.639376Z",
     "iopub.status.busy": "2022-01-25T05:49:16.638676Z",
     "iopub.status.idle": "2022-01-25T05:49:16.646298Z",
     "shell.execute_reply": "2022-01-25T05:49:16.646911Z",
     "shell.execute_reply.started": "2021-08-30T09:16:34.821174Z"
    },
    "papermill": {
     "duration": 0.037623,
     "end_time": "2022-01-25T05:49:16.647076",
     "exception": false,
     "start_time": "2022-01-25T05:49:16.609453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colNames = [col for col in list(train.columns)\n",
    "            if col not in {\"stock_id\", \"time_id\", \"target\", \"row_id\"}]\n",
    "len(colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3064c540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T05:49:16.702789Z",
     "iopub.status.busy": "2022-01-25T05:49:16.702023Z",
     "iopub.status.idle": "2022-01-25T05:49:19.183300Z",
     "shell.execute_reply": "2022-01-25T05:49:19.184169Z",
     "shell.execute_reply.started": "2021-08-30T09:16:34.834125Z"
    },
    "papermill": {
     "duration": 2.51312,
     "end_time": "2022-01-25T05:49:19.184421",
     "exception": false,
     "start_time": "2022-01-25T05:49:16.671301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "[81]\n",
      "[8, 80]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# making agg features\n",
    "\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b9d761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T05:49:19.242693Z",
     "iopub.status.busy": "2022-01-25T05:49:19.242001Z",
     "iopub.status.idle": "2022-01-25T05:49:19.374383Z",
     "shell.execute_reply": "2022-01-25T05:49:19.373882Z",
     "shell.execute_reply.started": "2021-08-30T09:16:37.275415Z"
    },
    "papermill": {
     "duration": 0.164022,
     "end_time": "2022-01-25T05:49:19.374552",
     "exception": false,
     "start_time": "2022-01-25T05:49:19.210530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c58442e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T05:49:19.444304Z",
     "iopub.status.busy": "2022-01-25T05:49:19.443573Z",
     "iopub.status.idle": "2022-01-25T05:49:31.979052Z",
     "shell.execute_reply": "2022-01-25T05:49:31.978444Z",
     "shell.execute_reply.started": "2021-08-30T09:16:37.484812Z"
    },
    "papermill": {
     "duration": 12.578696,
     "end_time": "2022-01-25T05:49:31.979206",
     "exception": false,
     "start_time": "2022-01-25T05:49:19.400510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] \n",
    "train = pd.merge(train,mat1[nnn],how='left',on='time_id')\n",
    "test = pd.merge(test,mat2[nnn],how='left',on='time_id')\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "# input more target distribution characteristics\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def rv(series_log_return):\n",
    "    return np.sqrt(np.sum((series_log_return-np.mean(series_log_return))**2))\n",
    "\n",
    "create_feature_dict = {\n",
    "        'mean':np.mean,\n",
    "        'median':np.median\n",
    "#         'std':rv,\n",
    "#         'skew':skew,\n",
    "#         'kurtosis':kurtosis\n",
    "            }\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "for k in create_feature_dict:\n",
    "    stock_id_target_stat = train.groupby('stock_id')['target'].apply(create_feature_dict[k])\n",
    "    test['stock_id_target_{}'.format(k)] = test['stock_id'].map(stock_id_target_stat) # test_set\n",
    "\n",
    "    #training\n",
    "    tmp = np.repeat(np.nan, train.shape[0])\n",
    "    kf = KFold(n_splits = 10, shuffle=True,random_state = 19970201)\n",
    "    for idx_1, idx_2 in kf.split(train):\n",
    "        target_stat = train.iloc[idx_1].groupby('stock_id')['target'].apply(create_feature_dict[k])\n",
    "\n",
    "        tmp[idx_2] = train['stock_id'].iloc[idx_2].map(target_stat)\n",
    "    train['stock_id_target_{}'.format(k)] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b1a5235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T05:49:32.153278Z",
     "iopub.status.busy": "2022-01-25T05:49:32.152448Z",
     "iopub.status.idle": "2022-01-25T05:49:32.155865Z",
     "shell.execute_reply": "2022-01-25T05:49:32.156359Z",
     "shell.execute_reply.started": "2021-08-30T09:16:46.1145Z"
    },
    "papermill": {
     "duration": 0.15108,
     "end_time": "2022-01-25T05:49:32.156547",
     "exception": false,
     "start_time": "2022-01-25T05:49:32.005467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del mat1,mat2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad89714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T05:49:32.213081Z",
     "iopub.status.busy": "2022-01-25T05:49:32.212078Z",
     "iopub.status.idle": "2022-01-25T06:46:36.357612Z",
     "shell.execute_reply": "2022-01-25T06:46:36.358100Z",
     "shell.execute_reply.started": "2021-08-30T09:16:46.238183Z"
    },
    "papermill": {
     "duration": 3424.175468,
     "end_time": "2022-01-25T06:46:36.358306",
     "exception": false,
     "start_time": "2022-01-25T05:49:32.182838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's l2: 2.39298e-07\ttraining's RMSPE: 0.226236\tvalid_1's l2: 2.40718e-07\tvalid_1's RMSPE: 0.227723\n",
      "[500]\ttraining's l2: 2.0725e-07\ttraining's RMSPE: 0.210543\tvalid_1's l2: 2.11575e-07\tvalid_1's RMSPE: 0.213493\n",
      "[750]\ttraining's l2: 1.96474e-07\ttraining's RMSPE: 0.204996\tvalid_1's l2: 2.02858e-07\tvalid_1's RMSPE: 0.209049\n",
      "[1000]\ttraining's l2: 1.88901e-07\ttraining's RMSPE: 0.201006\tvalid_1's l2: 1.97007e-07\tvalid_1's RMSPE: 0.206012\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 1.88901e-07\ttraining's RMSPE: 0.201006\tvalid_1's l2: 1.97007e-07\tvalid_1's RMSPE: 0.206012\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's l2: 2.38576e-07\ttraining's RMSPE: 0.226289\tvalid_1's l2: 2.40949e-07\tvalid_1's RMSPE: 0.226244\n",
      "[500]\ttraining's l2: 2.07116e-07\ttraining's RMSPE: 0.210842\tvalid_1's l2: 2.12861e-07\tvalid_1's RMSPE: 0.212648\n",
      "[750]\ttraining's l2: 1.96169e-07\ttraining's RMSPE: 0.205195\tvalid_1's l2: 2.03649e-07\tvalid_1's RMSPE: 0.207996\n",
      "[1000]\ttraining's l2: 1.8836e-07\ttraining's RMSPE: 0.201069\tvalid_1's l2: 1.97145e-07\tvalid_1's RMSPE: 0.204647\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 1.8836e-07\ttraining's RMSPE: 0.201069\tvalid_1's l2: 1.97145e-07\tvalid_1's RMSPE: 0.204647\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's l2: 2.37829e-07\ttraining's RMSPE: 0.225533\tvalid_1's l2: 2.78195e-07\tvalid_1's RMSPE: 0.244842\n",
      "[500]\ttraining's l2: 2.06689e-07\ttraining's RMSPE: 0.21025\tvalid_1's l2: 2.41253e-07\tvalid_1's RMSPE: 0.228007\n",
      "[750]\ttraining's l2: 1.95985e-07\ttraining's RMSPE: 0.204733\tvalid_1's l2: 2.29811e-07\tvalid_1's RMSPE: 0.222535\n",
      "[1000]\ttraining's l2: 1.88439e-07\ttraining's RMSPE: 0.200753\tvalid_1's l2: 2.23094e-07\tvalid_1's RMSPE: 0.219258\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 1.88439e-07\ttraining's RMSPE: 0.200753\tvalid_1's l2: 2.23094e-07\tvalid_1's RMSPE: 0.219258\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's l2: 2.38118e-07\ttraining's RMSPE: 0.226073\tvalid_1's l2: 2.45171e-07\tvalid_1's RMSPE: 0.228215\n",
      "[500]\ttraining's l2: 2.06531e-07\ttraining's RMSPE: 0.210545\tvalid_1's l2: 2.16766e-07\tvalid_1's RMSPE: 0.214588\n",
      "[750]\ttraining's l2: 1.95939e-07\ttraining's RMSPE: 0.205075\tvalid_1's l2: 2.08171e-07\tvalid_1's RMSPE: 0.210291\n",
      "[1000]\ttraining's l2: 1.88415e-07\ttraining's RMSPE: 0.201099\tvalid_1's l2: 2.02017e-07\tvalid_1's RMSPE: 0.207159\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 1.88415e-07\ttraining's RMSPE: 0.201099\tvalid_1's l2: 2.02017e-07\tvalid_1's RMSPE: 0.207159\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's l2: 2.39056e-07\ttraining's RMSPE: 0.226153\tvalid_1's l2: 2.4304e-07\tvalid_1's RMSPE: 0.228693\n",
      "[500]\ttraining's l2: 2.07416e-07\ttraining's RMSPE: 0.210656\tvalid_1's l2: 2.13347e-07\tvalid_1's RMSPE: 0.214268\n",
      "[750]\ttraining's l2: 1.96731e-07\ttraining's RMSPE: 0.205158\tvalid_1's l2: 2.05121e-07\tvalid_1's RMSPE: 0.210097\n",
      "[1000]\ttraining's l2: 1.89336e-07\ttraining's RMSPE: 0.201266\tvalid_1's l2: 1.99548e-07\tvalid_1's RMSPE: 0.207223\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 1.89336e-07\ttraining's RMSPE: 0.201266\tvalid_1's l2: 1.99548e-07\tvalid_1's RMSPE: 0.207223\n",
      "Our out of folds RMSPE is 0.208926713133761\n",
      "Training fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's l2: 2.05897e-07\ttraining's RMSPE: 0.209854\tvalid_1's l2: 2.10609e-07\tvalid_1's RMSPE: 0.213005\n",
      "[500]\ttraining's l2: 1.92125e-07\ttraining's RMSPE: 0.202714\tvalid_1's l2: 1.99397e-07\tvalid_1's RMSPE: 0.207258\n",
      "[750]\ttraining's l2: 1.83397e-07\ttraining's RMSPE: 0.198056\tvalid_1's l2: 1.92417e-07\tvalid_1's RMSPE: 0.203598\n",
      "[1000]\ttraining's l2: 1.76923e-07\ttraining's RMSPE: 0.194529\tvalid_1's l2: 1.87222e-07\tvalid_1's RMSPE: 0.200831\n",
      "[1250]\ttraining's l2: 1.71726e-07\ttraining's RMSPE: 0.19165\tvalid_1's l2: 1.83177e-07\tvalid_1's RMSPE: 0.19865\n",
      "[1500]\ttraining's l2: 1.67573e-07\ttraining's RMSPE: 0.189319\tvalid_1's l2: 1.80227e-07\tvalid_1's RMSPE: 0.197043\n",
      "[1750]\ttraining's l2: 1.63949e-07\ttraining's RMSPE: 0.18726\tvalid_1's l2: 1.77411e-07\tvalid_1's RMSPE: 0.195498\n",
      "[2000]\ttraining's l2: 1.6096e-07\ttraining's RMSPE: 0.185546\tvalid_1's l2: 1.75413e-07\tvalid_1's RMSPE: 0.194394\n",
      "[2250]\ttraining's l2: 1.5848e-07\ttraining's RMSPE: 0.184111\tvalid_1's l2: 1.7375e-07\tvalid_1's RMSPE: 0.19347\n",
      "[2500]\ttraining's l2: 1.56307e-07\ttraining's RMSPE: 0.182844\tvalid_1's l2: 1.72376e-07\tvalid_1's RMSPE: 0.192704\n",
      "[2750]\ttraining's l2: 1.5413e-07\ttraining's RMSPE: 0.181567\tvalid_1's l2: 1.71112e-07\tvalid_1's RMSPE: 0.191996\n",
      "[3000]\ttraining's l2: 1.52235e-07\ttraining's RMSPE: 0.180447\tvalid_1's l2: 1.70219e-07\tvalid_1's RMSPE: 0.191494\n",
      "[3250]\ttraining's l2: 1.50562e-07\ttraining's RMSPE: 0.179453\tvalid_1's l2: 1.69343e-07\tvalid_1's RMSPE: 0.191001\n",
      "[3500]\ttraining's l2: 1.48883e-07\ttraining's RMSPE: 0.178449\tvalid_1's l2: 1.68566e-07\tvalid_1's RMSPE: 0.190562\n",
      "[3750]\ttraining's l2: 1.47515e-07\ttraining's RMSPE: 0.177628\tvalid_1's l2: 1.68039e-07\tvalid_1's RMSPE: 0.190264\n",
      "[4000]\ttraining's l2: 1.46066e-07\ttraining's RMSPE: 0.176753\tvalid_1's l2: 1.6746e-07\tvalid_1's RMSPE: 0.189936\n",
      "[4250]\ttraining's l2: 1.44677e-07\ttraining's RMSPE: 0.175911\tvalid_1's l2: 1.6699e-07\tvalid_1's RMSPE: 0.18967\n",
      "[4500]\ttraining's l2: 1.43464e-07\ttraining's RMSPE: 0.175172\tvalid_1's l2: 1.6661e-07\tvalid_1's RMSPE: 0.189453\n",
      "[4750]\ttraining's l2: 1.42284e-07\ttraining's RMSPE: 0.17445\tvalid_1's l2: 1.66248e-07\tvalid_1's RMSPE: 0.189248\n",
      "[5000]\ttraining's l2: 1.41122e-07\ttraining's RMSPE: 0.173736\tvalid_1's l2: 1.65862e-07\tvalid_1's RMSPE: 0.189028\n",
      "[5250]\ttraining's l2: 1.40074e-07\ttraining's RMSPE: 0.17309\tvalid_1's l2: 1.65322e-07\tvalid_1's RMSPE: 0.18872\n",
      "[5500]\ttraining's l2: 1.39037e-07\ttraining's RMSPE: 0.172448\tvalid_1's l2: 1.65032e-07\tvalid_1's RMSPE: 0.188554\n",
      "[5750]\ttraining's l2: 1.3802e-07\ttraining's RMSPE: 0.171816\tvalid_1's l2: 1.64701e-07\tvalid_1's RMSPE: 0.188365\n",
      "Early stopping, best iteration is:\n",
      "[5757]\ttraining's l2: 1.37989e-07\ttraining's RMSPE: 0.171796\tvalid_1's l2: 1.64676e-07\tvalid_1's RMSPE: 0.188351\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's l2: 2.05969e-07\ttraining's RMSPE: 0.210258\tvalid_1's l2: 2.10749e-07\tvalid_1's RMSPE: 0.211591\n",
      "[500]\ttraining's l2: 1.92617e-07\ttraining's RMSPE: 0.203328\tvalid_1's l2: 1.99116e-07\tvalid_1's RMSPE: 0.205668\n",
      "[750]\ttraining's l2: 1.83494e-07\ttraining's RMSPE: 0.198455\tvalid_1's l2: 1.91493e-07\tvalid_1's RMSPE: 0.201693\n",
      "[1000]\ttraining's l2: 1.77122e-07\ttraining's RMSPE: 0.194979\tvalid_1's l2: 1.86522e-07\tvalid_1's RMSPE: 0.199058\n",
      "[1250]\ttraining's l2: 1.71768e-07\ttraining's RMSPE: 0.192009\tvalid_1's l2: 1.82295e-07\tvalid_1's RMSPE: 0.196789\n",
      "[1500]\ttraining's l2: 1.67304e-07\ttraining's RMSPE: 0.189498\tvalid_1's l2: 1.78848e-07\tvalid_1's RMSPE: 0.19492\n",
      "[1750]\ttraining's l2: 1.63714e-07\ttraining's RMSPE: 0.187453\tvalid_1's l2: 1.7634e-07\tvalid_1's RMSPE: 0.193548\n",
      "[2000]\ttraining's l2: 1.60734e-07\ttraining's RMSPE: 0.18574\tvalid_1's l2: 1.74311e-07\tvalid_1's RMSPE: 0.192431\n",
      "[2250]\ttraining's l2: 1.58083e-07\ttraining's RMSPE: 0.184202\tvalid_1's l2: 1.72659e-07\tvalid_1's RMSPE: 0.191517\n",
      "[2500]\ttraining's l2: 1.55537e-07\ttraining's RMSPE: 0.182712\tvalid_1's l2: 1.71046e-07\tvalid_1's RMSPE: 0.19062\n",
      "[2750]\ttraining's l2: 1.53483e-07\ttraining's RMSPE: 0.181502\tvalid_1's l2: 1.69926e-07\tvalid_1's RMSPE: 0.189996\n",
      "[3000]\ttraining's l2: 1.51446e-07\ttraining's RMSPE: 0.180294\tvalid_1's l2: 1.68806e-07\tvalid_1's RMSPE: 0.189369\n",
      "[3250]\ttraining's l2: 1.49637e-07\ttraining's RMSPE: 0.179214\tvalid_1's l2: 1.67882e-07\tvalid_1's RMSPE: 0.188849\n",
      "[3500]\ttraining's l2: 1.47975e-07\ttraining's RMSPE: 0.178215\tvalid_1's l2: 1.6707e-07\tvalid_1's RMSPE: 0.188392\n",
      "[3750]\ttraining's l2: 1.46509e-07\ttraining's RMSPE: 0.177331\tvalid_1's l2: 1.66432e-07\tvalid_1's RMSPE: 0.188032\n",
      "[4000]\ttraining's l2: 1.45055e-07\ttraining's RMSPE: 0.176448\tvalid_1's l2: 1.65812e-07\tvalid_1's RMSPE: 0.187682\n",
      "[4250]\ttraining's l2: 1.43727e-07\ttraining's RMSPE: 0.175639\tvalid_1's l2: 1.65263e-07\tvalid_1's RMSPE: 0.187371\n",
      "[4500]\ttraining's l2: 1.4249e-07\ttraining's RMSPE: 0.174881\tvalid_1's l2: 1.64817e-07\tvalid_1's RMSPE: 0.187117\n",
      "[4750]\ttraining's l2: 1.41339e-07\ttraining's RMSPE: 0.174174\tvalid_1's l2: 1.6441e-07\tvalid_1's RMSPE: 0.186886\n",
      "[5000]\ttraining's l2: 1.40209e-07\ttraining's RMSPE: 0.173476\tvalid_1's l2: 1.64018e-07\tvalid_1's RMSPE: 0.186663\n",
      "[5250]\ttraining's l2: 1.39141e-07\ttraining's RMSPE: 0.172814\tvalid_1's l2: 1.6363e-07\tvalid_1's RMSPE: 0.186443\n",
      "[5500]\ttraining's l2: 1.38122e-07\ttraining's RMSPE: 0.17218\tvalid_1's l2: 1.63294e-07\tvalid_1's RMSPE: 0.186251\n",
      "[5750]\ttraining's l2: 1.37153e-07\ttraining's RMSPE: 0.171575\tvalid_1's l2: 1.62958e-07\tvalid_1's RMSPE: 0.186059\n",
      "Early stopping, best iteration is:\n",
      "[5845]\ttraining's l2: 1.36795e-07\ttraining's RMSPE: 0.171351\tvalid_1's l2: 1.62859e-07\tvalid_1's RMSPE: 0.186002\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's l2: 2.05625e-07\ttraining's RMSPE: 0.209708\tvalid_1's l2: 2.3269e-07\tvalid_1's RMSPE: 0.223924\n",
      "[500]\ttraining's l2: 1.91881e-07\ttraining's RMSPE: 0.202579\tvalid_1's l2: 2.19324e-07\tvalid_1's RMSPE: 0.217398\n",
      "[750]\ttraining's l2: 1.83203e-07\ttraining's RMSPE: 0.197944\tvalid_1's l2: 2.12147e-07\tvalid_1's RMSPE: 0.213812\n",
      "[1000]\ttraining's l2: 1.76288e-07\ttraining's RMSPE: 0.194173\tvalid_1's l2: 2.06154e-07\tvalid_1's RMSPE: 0.21077\n",
      "[1250]\ttraining's l2: 1.71045e-07\ttraining's RMSPE: 0.191264\tvalid_1's l2: 2.01802e-07\tvalid_1's RMSPE: 0.208533\n",
      "[1500]\ttraining's l2: 1.67013e-07\ttraining's RMSPE: 0.188996\tvalid_1's l2: 1.99314e-07\tvalid_1's RMSPE: 0.207244\n",
      "[1750]\ttraining's l2: 1.63515e-07\ttraining's RMSPE: 0.187006\tvalid_1's l2: 1.96613e-07\tvalid_1's RMSPE: 0.205834\n",
      "[2000]\ttraining's l2: 1.60548e-07\ttraining's RMSPE: 0.185302\tvalid_1's l2: 1.94633e-07\tvalid_1's RMSPE: 0.204796\n",
      "[2250]\ttraining's l2: 1.57914e-07\ttraining's RMSPE: 0.183776\tvalid_1's l2: 1.93121e-07\tvalid_1's RMSPE: 0.203999\n",
      "[2500]\ttraining's l2: 1.55586e-07\ttraining's RMSPE: 0.182416\tvalid_1's l2: 1.91528e-07\tvalid_1's RMSPE: 0.203156\n",
      "[2750]\ttraining's l2: 1.53507e-07\ttraining's RMSPE: 0.181193\tvalid_1's l2: 1.90243e-07\tvalid_1's RMSPE: 0.202473\n",
      "Early stopping, best iteration is:\n",
      "[2933]\ttraining's l2: 1.52118e-07\ttraining's RMSPE: 0.180372\tvalid_1's l2: 1.89285e-07\tvalid_1's RMSPE: 0.201963\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's l2: 2.05136e-07\ttraining's RMSPE: 0.209832\tvalid_1's l2: 2.15808e-07\tvalid_1's RMSPE: 0.214113\n",
      "[500]\ttraining's l2: 1.91928e-07\ttraining's RMSPE: 0.202965\tvalid_1's l2: 2.04435e-07\tvalid_1's RMSPE: 0.208395\n",
      "[750]\ttraining's l2: 1.82831e-07\ttraining's RMSPE: 0.198096\tvalid_1's l2: 1.96439e-07\tvalid_1's RMSPE: 0.204279\n",
      "[1000]\ttraining's l2: 1.7615e-07\ttraining's RMSPE: 0.194444\tvalid_1's l2: 1.90779e-07\tvalid_1's RMSPE: 0.201314\n",
      "[1250]\ttraining's l2: 1.71124e-07\ttraining's RMSPE: 0.191649\tvalid_1's l2: 1.86694e-07\tvalid_1's RMSPE: 0.199148\n",
      "[1500]\ttraining's l2: 1.6698e-07\ttraining's RMSPE: 0.189314\tvalid_1's l2: 1.8375e-07\tvalid_1's RMSPE: 0.197571\n",
      "[1750]\ttraining's l2: 1.63385e-07\ttraining's RMSPE: 0.187265\tvalid_1's l2: 1.81191e-07\tvalid_1's RMSPE: 0.196191\n",
      "[2000]\ttraining's l2: 1.6037e-07\ttraining's RMSPE: 0.18553\tvalid_1's l2: 1.79048e-07\tvalid_1's RMSPE: 0.195027\n",
      "[2250]\ttraining's l2: 1.5783e-07\ttraining's RMSPE: 0.184054\tvalid_1's l2: 1.7743e-07\tvalid_1's RMSPE: 0.194144\n",
      "[2500]\ttraining's l2: 1.55333e-07\ttraining's RMSPE: 0.182593\tvalid_1's l2: 1.75776e-07\tvalid_1's RMSPE: 0.193236\n",
      "[2750]\ttraining's l2: 1.5323e-07\ttraining's RMSPE: 0.181352\tvalid_1's l2: 1.74747e-07\tvalid_1's RMSPE: 0.19267\n",
      "[3000]\ttraining's l2: 1.51473e-07\ttraining's RMSPE: 0.18031\tvalid_1's l2: 1.73879e-07\tvalid_1's RMSPE: 0.192191\n",
      "[3250]\ttraining's l2: 1.49807e-07\ttraining's RMSPE: 0.179316\tvalid_1's l2: 1.73172e-07\tvalid_1's RMSPE: 0.1918\n",
      "[3500]\ttraining's l2: 1.4815e-07\ttraining's RMSPE: 0.178321\tvalid_1's l2: 1.72406e-07\tvalid_1's RMSPE: 0.191375\n",
      "[3750]\ttraining's l2: 1.46666e-07\ttraining's RMSPE: 0.177426\tvalid_1's l2: 1.7171e-07\tvalid_1's RMSPE: 0.190989\n",
      "[4000]\ttraining's l2: 1.45311e-07\ttraining's RMSPE: 0.176604\tvalid_1's l2: 1.71167e-07\tvalid_1's RMSPE: 0.190687\n",
      "[4250]\ttraining's l2: 1.43945e-07\ttraining's RMSPE: 0.175772\tvalid_1's l2: 1.70607e-07\tvalid_1's RMSPE: 0.190375\n",
      "[4500]\ttraining's l2: 1.42689e-07\ttraining's RMSPE: 0.175004\tvalid_1's l2: 1.70257e-07\tvalid_1's RMSPE: 0.190179\n",
      "Early stopping, best iteration is:\n",
      "[4479]\ttraining's l2: 1.42802e-07\ttraining's RMSPE: 0.175073\tvalid_1's l2: 1.70223e-07\tvalid_1's RMSPE: 0.19016\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's l2: 2.05364e-07\ttraining's RMSPE: 0.209611\tvalid_1's l2: 2.12412e-07\tvalid_1's RMSPE: 0.213798\n",
      "[500]\ttraining's l2: 1.91924e-07\ttraining's RMSPE: 0.202636\tvalid_1's l2: 2.01624e-07\tvalid_1's RMSPE: 0.208298\n",
      "[750]\ttraining's l2: 1.83511e-07\ttraining's RMSPE: 0.198145\tvalid_1's l2: 1.95284e-07\tvalid_1's RMSPE: 0.204997\n",
      "[1000]\ttraining's l2: 1.76951e-07\ttraining's RMSPE: 0.194571\tvalid_1's l2: 1.90134e-07\tvalid_1's RMSPE: 0.202275\n",
      "[1250]\ttraining's l2: 1.71891e-07\ttraining's RMSPE: 0.191769\tvalid_1's l2: 1.86496e-07\tvalid_1's RMSPE: 0.200331\n",
      "[1500]\ttraining's l2: 1.67764e-07\ttraining's RMSPE: 0.189453\tvalid_1's l2: 1.83479e-07\tvalid_1's RMSPE: 0.198704\n",
      "[1750]\ttraining's l2: 1.64296e-07\ttraining's RMSPE: 0.187485\tvalid_1's l2: 1.80906e-07\tvalid_1's RMSPE: 0.197306\n",
      "[2000]\ttraining's l2: 1.61401e-07\ttraining's RMSPE: 0.185826\tvalid_1's l2: 1.79095e-07\tvalid_1's RMSPE: 0.196316\n",
      "[2250]\ttraining's l2: 1.58872e-07\ttraining's RMSPE: 0.184364\tvalid_1's l2: 1.77624e-07\tvalid_1's RMSPE: 0.195508\n",
      "[2500]\ttraining's l2: 1.56462e-07\ttraining's RMSPE: 0.182961\tvalid_1's l2: 1.76483e-07\tvalid_1's RMSPE: 0.194879\n",
      "Early stopping, best iteration is:\n",
      "[2576]\ttraining's l2: 1.55833e-07\ttraining's RMSPE: 0.182592\tvalid_1's l2: 1.76177e-07\tvalid_1's RMSPE: 0.19471\n",
      "Our out of folds RMSPE is 0.19231982420770868\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "seed0=2021\n",
    "params0 = {\n",
    "    'objective': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_depth': -1,\n",
    "    'max_bin':100,\n",
    "    'min_data_in_leaf':500,\n",
    "    'learning_rate': 0.01,\n",
    "    'subsample': 0.72,\n",
    "    'subsample_freq': 4,\n",
    "    'feature_fraction': 0.5,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 1.0,\n",
    "    'categorical_column':[0],\n",
    "    'seed':seed0,\n",
    "    'feature_fraction_seed': seed0,\n",
    "    'bagging_seed': seed0,\n",
    "    'drop_seed': seed0,\n",
    "    'data_random_seed': seed0,\n",
    "    'n_jobs':-1,\n",
    "    'verbose': -1}\n",
    "\n",
    "seed2 = 29\n",
    "params2 = {\n",
    "        'learning_rate': 0.05,        \n",
    "        'lambda_l1': 2.154360665259325,\n",
    "        'lambda_l2': 6.711089761523827,\n",
    "        'num_leaves': 2769,\n",
    "        'min_sum_hessian_in_leaf': 20.44437160769411,\n",
    "        'feature_fraction': 0.7921473067441019,\n",
    "        'feature_fraction_bynode': 0.8083803860191322,\n",
    "        'bagging_fraction': 0.9726755660563261,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 1690,\n",
    "        'max_depth': 4,\n",
    "        'seed': seed2,\n",
    "        'feature_fraction_seed': seed2,\n",
    "        'bagging_seed': seed2,\n",
    "        'drop_seed': seed2,\n",
    "        'data_random_seed': seed2,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "    } \n",
    "# Function to early stop with root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "def train_and_evaluate_lgb(train, test, params,boost=1000):\n",
    "    # Hyperparammeters (just basic)\n",
    "    \n",
    "    features = [col for col in train.columns if col not in {\"time_id\", \"target\", \"row_id\"}]\n",
    "    y = train['target']\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 2021, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = train.iloc[trn_ind], train.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train[features], y_train, weight = train_weights)\n",
    "        val_dataset = lgb.Dataset(x_val[features], y_val, weight = val_weights)\n",
    "        model = lgb.train(params = params,\n",
    "                          num_boost_round=boost,\n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          verbose_eval = 250,\n",
    "                          early_stopping_rounds=50,\n",
    "                          feval = feval_rmspe)\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val[features])\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(test[features]) / 5\n",
    "    rmspe_score = rmspe(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    lgb.plot_importance(model,max_num_features=20)\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "# Traing and evaluate\n",
    "predictions_lgb= train_and_evaluate_lgb(train, test,params0)\n",
    "predictions_lgb2= train_and_evaluate_lgb(train, test,params2,boost=10000)\n",
    "test['target'] = predictions_lgb\n",
    "test[['row_id', 'target']].to_csv('submission.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55731718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:46:36.501874Z",
     "iopub.status.busy": "2022-01-25T06:46:36.501204Z",
     "iopub.status.idle": "2022-01-25T06:46:36.506827Z",
     "shell.execute_reply": "2022-01-25T06:46:36.507397Z",
     "shell.execute_reply.started": "2021-08-30T09:48:18.063276Z"
    },
    "papermill": {
     "duration": 0.079124,
     "end_time": "2022-01-25T06:46:36.507574",
     "exception": false,
     "start_time": "2022-01-25T06:46:36.428450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428932, 250)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4747bd20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:46:36.651128Z",
     "iopub.status.busy": "2022-01-25T06:46:36.650384Z",
     "iopub.status.idle": "2022-01-25T06:46:42.998515Z",
     "shell.execute_reply": "2022-01-25T06:46:42.997898Z",
     "shell.execute_reply.started": "2021-08-30T09:48:18.071101Z"
    },
    "papermill": {
     "duration": 6.420829,
     "end_time": "2022-01-25T06:46:42.998680",
     "exception": false,
     "start_time": "2022-01-25T06:46:36.577851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "def root_mean_squared_per_error(y_true, y_pred):\n",
    "         return K.sqrt(K.mean(K.square( (y_true - y_pred)/ y_true )))\n",
    "    \n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=0,\n",
    "    mode='min',restore_best_weights=True)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=7, verbose=0,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88a5c227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:46:43.144488Z",
     "iopub.status.busy": "2022-01-25T06:46:43.143388Z",
     "iopub.status.idle": "2022-01-25T06:46:54.121491Z",
     "shell.execute_reply": "2022-01-25T06:46:54.120938Z",
     "shell.execute_reply.started": "2021-08-30T09:48:25.093899Z"
    },
    "papermill": {
     "duration": 11.051259,
     "end_time": "2022-01-25T06:46:54.121646",
     "exception": false,
     "start_time": "2022-01-25T06:46:43.070387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kfold based on the knn++ algorithm\n",
    "\n",
    "out_train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "out_train = out_train.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "#out_train[out_train.isna().any(axis=1)]\n",
    "out_train = out_train.fillna(out_train.mean())\n",
    "out_train.head()\n",
    "\n",
    "# code to add the just the read data after first execution\n",
    "\n",
    "# data separation based on knn ++\n",
    "nfolds = 5 # number of folds\n",
    "index = []\n",
    "totDist = []\n",
    "values = []\n",
    "# generates a matriz with the values of \n",
    "mat = out_train.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "mat = scaler.fit_transform(mat)\n",
    "\n",
    "nind = int(mat.shape[0]/nfolds) # number of individuals\n",
    "\n",
    "# adds index in the last column\n",
    "mat = np.c_[mat,np.arange(mat.shape[0])]\n",
    "\n",
    "\n",
    "lineNumber = np.random.choice(np.array(mat.shape[0]), size=nfolds, replace=False)\n",
    "\n",
    "lineNumber = np.sort(lineNumber)[::-1]\n",
    "\n",
    "for n in range(nfolds):\n",
    "    totDist.append(np.zeros(mat.shape[0]-nfolds))\n",
    "\n",
    "# saves index\n",
    "for n in range(nfolds):\n",
    "    \n",
    "    values.append([lineNumber[n]])    \n",
    "\n",
    "\n",
    "s=[]\n",
    "for n in range(nfolds):\n",
    "    s.append(mat[lineNumber[n],:])\n",
    "    \n",
    "    mat = np.delete(mat, obj=lineNumber[n], axis=0)\n",
    "\n",
    "for n in range(nind-1):    \n",
    "\n",
    "    luck = np.random.uniform(0,1,nfolds)\n",
    "    \n",
    "    for cycle in range(nfolds):\n",
    "         # saves the values of index           \n",
    "\n",
    "        s[cycle] = np.matlib.repmat(s[cycle], mat.shape[0], 1)\n",
    "\n",
    "        sumDist = np.sum( (mat[:,:-1] - s[cycle][:,:-1])**2 , axis=1)   \n",
    "        totDist[cycle] += sumDist        \n",
    "                \n",
    "        # probabilities\n",
    "        f = totDist[cycle]/np.sum(totDist[cycle]) # normalizing the totdist\n",
    "        j = 0\n",
    "        kn = 0\n",
    "        for val in f:\n",
    "            j += val        \n",
    "            if (j > luck[cycle]): # the column was selected\n",
    "                break\n",
    "            kn +=1\n",
    "        lineNumber[cycle] = kn\n",
    "        \n",
    "        # delete line of the value added    \n",
    "        for n_iter in range(nfolds):\n",
    "            \n",
    "            totDist[n_iter] = np.delete(totDist[n_iter],obj=lineNumber[cycle], axis=0)\n",
    "            j= 0\n",
    "        \n",
    "        s[cycle] = mat[lineNumber[cycle],:]\n",
    "        values[cycle].append(int(mat[lineNumber[cycle],-1]))\n",
    "        mat = np.delete(mat, obj=lineNumber[cycle], axis=0)\n",
    "\n",
    "\n",
    "for n_mod in range(nfolds):\n",
    "    values[n_mod] = out_train.index[values[n_mod]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93b27a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:46:54.266639Z",
     "iopub.status.busy": "2022-01-25T06:46:54.265977Z",
     "iopub.status.idle": "2022-01-25T06:47:18.998858Z",
     "shell.execute_reply": "2022-01-25T06:47:18.999524Z",
     "shell.execute_reply.started": "2021-08-30T09:48:37.824504Z"
    },
    "papermill": {
     "duration": 24.807483,
     "end_time": "2022-01-25T06:47:18.999708",
     "exception": false,
     "start_time": "2022-01-25T06:46:54.192225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#colNames.remove('row_id')\n",
    "train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "qt_train = []\n",
    "train_nn=train[colNames].copy()\n",
    "test_nn=test[colNames].copy()\n",
    "for col in colNames:\n",
    "    #print(col)\n",
    "    qt = QuantileTransformer(random_state=21,n_quantiles=2000, output_distribution='normal')\n",
    "    train_nn[col] = qt.fit_transform(train_nn[[col]])\n",
    "    test_nn[col] = qt.transform(test_nn[[col]])    \n",
    "    qt_train.append(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0221a5cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:47:19.165690Z",
     "iopub.status.busy": "2022-01-25T06:47:19.164696Z",
     "iopub.status.idle": "2022-01-25T06:47:19.177962Z",
     "shell.execute_reply": "2022-01-25T06:47:19.178560Z",
     "shell.execute_reply.started": "2021-08-30T09:49:07.242658Z"
    },
    "papermill": {
     "duration": 0.104074,
     "end_time": "2022-01-25T06:47:19.178744",
     "exception": false,
     "start_time": "2022-01-25T06:47:19.074670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_nn[['stock_id','time_id','target']]=train[['stock_id','time_id','target']]\n",
    "test_nn[['stock_id','time_id']]=test[['stock_id','time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8e0f369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:47:19.336552Z",
     "iopub.status.busy": "2022-01-25T06:47:19.335525Z",
     "iopub.status.idle": "2022-01-25T06:47:21.284672Z",
     "shell.execute_reply": "2022-01-25T06:47:21.285148Z",
     "shell.execute_reply.started": "2021-08-30T09:49:07.262216Z"
    },
    "papermill": {
     "duration": 2.025639,
     "end_time": "2022-01-25T06:47:21.285325",
     "exception": false,
     "start_time": "2022-01-25T06:47:19.259686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "[81]\n",
      "[8, 80]\n"
     ]
    }
   ],
   "source": [
    "# making agg features\n",
    "from sklearn.cluster import KMeans\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train_nn.loc[train_nn['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test_nn.loc[test_nn['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()\n",
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fa04657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:47:21.437368Z",
     "iopub.status.busy": "2022-01-25T06:47:21.436698Z",
     "iopub.status.idle": "2022-01-25T06:47:21.439273Z",
     "shell.execute_reply": "2022-01-25T06:47:21.438687Z",
     "shell.execute_reply.started": "2021-08-30T09:49:09.042483Z"
    },
    "papermill": {
     "duration": 0.08231,
     "end_time": "2022-01-25T06:47:21.439410",
     "exception": false,
     "start_time": "2022-01-25T06:47:21.357100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa2aabe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:47:21.590696Z",
     "iopub.status.busy": "2022-01-25T06:47:21.590021Z",
     "iopub.status.idle": "2022-01-25T06:47:21.718744Z",
     "shell.execute_reply": "2022-01-25T06:47:21.718163Z",
     "shell.execute_reply.started": "2021-08-30T09:49:09.054213Z"
    },
    "papermill": {
     "duration": 0.208105,
     "end_time": "2022-01-25T06:47:21.718897",
     "exception": false,
     "start_time": "2022-01-25T06:47:21.510792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6670cff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:47:21.873073Z",
     "iopub.status.busy": "2022-01-25T06:47:21.872358Z",
     "iopub.status.idle": "2022-01-25T06:47:25.580509Z",
     "shell.execute_reply": "2022-01-25T06:47:25.579877Z",
     "shell.execute_reply.started": "2021-08-30T09:49:09.239588Z"
    },
    "papermill": {
     "duration": 3.789758,
     "end_time": "2022-01-25T06:47:25.580649",
     "exception": false,
     "start_time": "2022-01-25T06:47:21.790891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "train_nn = pd.merge(train_nn,mat1[nnn],how='left',on='time_id')\n",
    "test_nn = pd.merge(test_nn,mat2[nnn],how='left',on='time_id')\n",
    "del mat1,mat2\n",
    "del train,test\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "# # input more target distribution characteristics\n",
    "# from scipy.stats import skew, kurtosis\n",
    "\n",
    "# def rv(series_log_return):\n",
    "#     return np.sqrt(np.sum((series_log_return-np.mean(series_log_return))**2))\n",
    "\n",
    "# create_feature_dict = {\n",
    "#         'mean':np.mean,\n",
    "#         'median':np.median\n",
    "# #         'std':rv,\n",
    "# #         'skew':skew,\n",
    "# #         'kurtosis':kurtosis\n",
    "#             }\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# for k in create_feature_dict:\n",
    "#     stock_id_target_stat = train_nn.groupby('stock_id')['target'].apply(create_feature_dict[k])\n",
    "#     test_nn['stock_id_target_{}'.format(k)] = test_nn['stock_id'].map(stock_id_target_stat) # test_set\n",
    "\n",
    "#     #training\n",
    "#     tmp = np.repeat(np.nan, train_nn.shape[0])\n",
    "#     kf = KFold(n_splits = 10, shuffle=True,random_state = 19970201)\n",
    "#     for idx_1, idx_2 in kf.split(train_nn):\n",
    "#         target_stat = train_nn.iloc[idx_1].groupby('stock_id')['target'].apply(create_feature_dict[k])\n",
    "\n",
    "#         tmp[idx_2] = train_nn['stock_id'].iloc[idx_2].map(target_stat)\n",
    "#     train_nn['stock_id_target_{}'.format(k)] = tmp\n",
    "    \n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5d57ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:47:25.738312Z",
     "iopub.status.busy": "2022-01-25T06:47:25.737248Z",
     "iopub.status.idle": "2022-01-25T06:47:25.767239Z",
     "shell.execute_reply": "2022-01-25T06:47:25.767741Z",
     "shell.execute_reply.started": "2021-08-30T09:49:14.890567Z"
    },
    "papermill": {
     "duration": 0.114897,
     "end_time": "2022-01-25T06:47:25.767924",
     "exception": false,
     "start_time": "2022-01-25T06:47:25.653027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://bignerdranch.com/blog/implementing-swish-activation-function-in-keras/\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "hidden_units = (128,64,32)\n",
    "stock_embedding_size = 24\n",
    "\n",
    "cat_data = train_nn['stock_id']\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n",
    "    num_input = keras.Input(shape=(244,), name='num_data')\n",
    "\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size, \n",
    "                                           input_length=1, name='stock_embedding')(stock_id_input)\n",
    "    stock_flattened = keras.layers.Flatten()(stock_embedded)\n",
    "    out = keras.layers.Concatenate()([stock_flattened, num_input])\n",
    "    \n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "\n",
    "        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n",
    "        \n",
    "\n",
    "    #out = keras.layers.Concatenate()([out, num_input])\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "    \n",
    "    model = keras.Model(\n",
    "    inputs = [stock_id_input, num_input],\n",
    "    outputs = out,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "886a215b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:47:25.918579Z",
     "iopub.status.busy": "2022-01-25T06:47:25.915059Z",
     "iopub.status.idle": "2022-01-25T06:47:25.921238Z",
     "shell.execute_reply": "2022-01-25T06:47:25.920737Z",
     "shell.execute_reply.started": "2021-08-30T09:49:14.922612Z"
    },
    "papermill": {
     "duration": 0.0812,
     "end_time": "2022-01-25T06:47:25.921387",
     "exception": false,
     "start_time": "2022-01-25T06:47:25.840187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "395aa37d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T06:47:26.075956Z",
     "iopub.status.busy": "2022-01-25T06:47:26.075201Z",
     "iopub.status.idle": "2022-01-25T06:59:55.369106Z",
     "shell.execute_reply": "2022-01-25T06:59:55.369707Z",
     "shell.execute_reply.started": "2021-08-30T09:49:14.930362Z"
    },
    "papermill": {
     "duration": 749.376163,
     "end_time": "2022-01-25T06:59:55.369899",
     "exception": false,
     "start_time": "2022-01-25T06:47:25.993736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   KMP_WARNINGS=0\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=4\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=false\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS: value is not defined\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2022-01-25 06:47:28.937689: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-01-25 06:47:31.207893: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "168/168 [==============================] - 4s 17ms/step - loss: 7.9538 - val_loss: 0.9252\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7948 - val_loss: 0.5556\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.4199 - val_loss: 0.4221\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.6164 - val_loss: 0.8540\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.4462 - val_loss: 0.3320\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.9753 - val_loss: 0.6375\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5825 - val_loss: 0.6130\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.5445 - val_loss: 0.6459\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.5110 - val_loss: 0.5125\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7496 - val_loss: 0.4977\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4323 - val_loss: 0.4253\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.4014 - val_loss: 0.4111\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2236 - val_loss: 0.2143\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2151 - val_loss: 0.2205\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2150 - val_loss: 0.2135\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2135 - val_loss: 0.2152\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2128 - val_loss: 0.2136\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2142 - val_loss: 0.2123\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2143 - val_loss: 0.2187\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2138 - val_loss: 0.2131\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2114 - val_loss: 0.2140\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2122 - val_loss: 0.2152\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.2139 - val_loss: 0.2210\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.2137 - val_loss: 0.2170\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 3s 21ms/step - loss: 0.2117 - val_loss: 0.2177\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2079 - val_loss: 0.2106\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2073 - val_loss: 0.2104\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2072 - val_loss: 0.2105\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2072 - val_loss: 0.2106\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2072 - val_loss: 0.2102\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2070 - val_loss: 0.2108\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2069 - val_loss: 0.2114\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2075 - val_loss: 0.2117\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2073 - val_loss: 0.2111\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2066 - val_loss: 0.2101\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2068 - val_loss: 0.2115\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2065 - val_loss: 0.2107\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2063 - val_loss: 0.2102\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2075 - val_loss: 0.2116\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2071 - val_loss: 0.2111\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2078 - val_loss: 0.2122\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2066 - val_loss: 0.2119\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2045 - val_loss: 0.2098\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2044 - val_loss: 0.2100\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2044 - val_loss: 0.2097\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2043 - val_loss: 0.2097\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2043 - val_loss: 0.2103\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2043 - val_loss: 0.2097\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2042 - val_loss: 0.2106\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2043 - val_loss: 0.2100\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2044 - val_loss: 0.2106\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2041 - val_loss: 0.2100\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2035 - val_loss: 0.2097\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2096\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2097\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2096\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2034 - val_loss: 0.2095\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2097\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2034 - val_loss: 0.2095\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2097\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2096\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2034 - val_loss: 0.2100\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2033 - val_loss: 0.2095\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2033 - val_loss: 0.2094\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2032 - val_loss: 0.2095\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2031 - val_loss: 0.2095\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2031 - val_loss: 0.2094\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2031 - val_loss: 0.2095\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2095\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2031 - val_loss: 0.2096\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2097\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2095\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2095\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2095\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2031 - val_loss: 0.2096\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2030 - val_loss: 0.2095\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2095\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2031 - val_loss: 0.2095\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2030 - val_loss: 0.2095\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2030 - val_loss: 0.2095\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2030 - val_loss: 0.2095\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2030 - val_loss: 0.2095\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2030 - val_loss: 0.2095\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2030 - val_loss: 0.2095\n",
      "Fold 1 NN: 0.20941\n",
      "CV 2/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 9.7349 - val_loss: 1.1152\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.8463 - val_loss: 0.8406\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.7288 - val_loss: 0.9384\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8613 - val_loss: 0.8833\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.8524 - val_loss: 0.5005\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.5661 - val_loss: 0.5688\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 1.0723 - val_loss: 0.3992\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.5860 - val_loss: 0.5536\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.6076 - val_loss: 0.6215\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.3548 - val_loss: 0.2892\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2774 - val_loss: 0.3845\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2941 - val_loss: 0.2473\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2929 - val_loss: 0.2726\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 1.9996 - val_loss: 0.3892\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2967 - val_loss: 0.3039\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2512 - val_loss: 0.2699\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2470 - val_loss: 0.2396\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2515 - val_loss: 0.2688\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2863 - val_loss: 0.2557\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2521 - val_loss: 0.2568\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2563 - val_loss: 0.2285\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2609 - val_loss: 0.2284\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2615 - val_loss: 0.2233\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2598 - val_loss: 0.2720\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2587 - val_loss: 0.2227\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2503 - val_loss: 0.2882\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2561 - val_loss: 0.2314\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2603 - val_loss: 0.2175\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2895 - val_loss: 0.2559\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2413 - val_loss: 0.2393\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2363 - val_loss: 0.2557\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2375 - val_loss: 0.2462\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2363 - val_loss: 0.2648\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2543 - val_loss: 0.2646\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2317 - val_loss: 0.2281\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2058 - val_loss: 0.2137\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2046 - val_loss: 0.2144\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2041 - val_loss: 0.2138\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2042 - val_loss: 0.2139\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2039 - val_loss: 0.2183\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2046 - val_loss: 0.2153\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2039 - val_loss: 0.2133\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2042 - val_loss: 0.2143\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2041 - val_loss: 0.2166\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2039 - val_loss: 0.2185\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2048 - val_loss: 0.2175\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2041 - val_loss: 0.2135\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2045 - val_loss: 0.2144\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2068 - val_loss: 0.2228\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2010 - val_loss: 0.2125\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2004 - val_loss: 0.2121\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2003 - val_loss: 0.2115\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2003 - val_loss: 0.2132\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2004 - val_loss: 0.2120\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2002 - val_loss: 0.2119\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2000 - val_loss: 0.2125\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2003 - val_loss: 0.2129\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2001 - val_loss: 0.2143\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2004 - val_loss: 0.2133\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1993 - val_loss: 0.2122\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1989 - val_loss: 0.2126\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1989 - val_loss: 0.2129\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1989 - val_loss: 0.2132\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1989 - val_loss: 0.2130\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1988 - val_loss: 0.2130\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.1988 - val_loss: 0.2129\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1985 - val_loss: 0.2122\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.1985 - val_loss: 0.2127\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1985 - val_loss: 0.2126\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1985 - val_loss: 0.2121\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1985 - val_loss: 0.2125\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.1985 - val_loss: 0.2124\n",
      "Fold 2 NN: 0.21151\n",
      "CV 3/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 7.8754 - val_loss: 0.5753\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5055 - val_loss: 0.3852\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3719 - val_loss: 0.3414\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7884 - val_loss: 0.5269\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5830 - val_loss: 0.4744\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5251 - val_loss: 0.3930\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.5022 - val_loss: 0.4052\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4504 - val_loss: 0.3699\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.6146 - val_loss: 0.3305\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3713 - val_loss: 0.3861\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.3488 - val_loss: 0.3717\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.3493 - val_loss: 0.3439\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2812 - val_loss: 0.2364\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2376 - val_loss: 0.2394\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2359 - val_loss: 0.2159\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2311 - val_loss: 0.2691\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2364 - val_loss: 0.2329\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2362 - val_loss: 0.2266\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2411 - val_loss: 0.2535\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2897 - val_loss: 0.2325\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2509 - val_loss: 0.3430\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2367 - val_loss: 0.2343\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2090 - val_loss: 0.2109\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2073 - val_loss: 0.2106\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2067 - val_loss: 0.2122\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2066 - val_loss: 0.2122\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2065 - val_loss: 0.2206\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2063 - val_loss: 0.2124\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2064 - val_loss: 0.2127\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2065 - val_loss: 0.2115\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2057 - val_loss: 0.2123\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2037 - val_loss: 0.2094\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2033 - val_loss: 0.2089\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2032 - val_loss: 0.2096\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2031 - val_loss: 0.2091\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2031 - val_loss: 0.2097\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2031 - val_loss: 0.2112\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2032 - val_loss: 0.2101\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2033 - val_loss: 0.2094\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2030 - val_loss: 0.2107\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2022 - val_loss: 0.2094\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2021 - val_loss: 0.2091\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2021 - val_loss: 0.2096\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2021 - val_loss: 0.2094\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2095\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2021 - val_loss: 0.2094\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2020 - val_loss: 0.2092\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2092\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2017 - val_loss: 0.2093\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2017 - val_loss: 0.2093\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2018 - val_loss: 0.2091\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2017 - val_loss: 0.2090\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2017 - val_loss: 0.2092\n",
      "Fold 3 NN: 0.20894\n",
      "CV 4/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 6.6268 - val_loss: 0.6470\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.7327 - val_loss: 0.9168\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.8132 - val_loss: 0.3969\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.8006 - val_loss: 0.7754\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6488 - val_loss: 0.5530\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.8960 - val_loss: 1.0296\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4683 - val_loss: 0.2468\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.4048 - val_loss: 0.6862\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.6812 - val_loss: 0.4106\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.4284 - val_loss: 0.4379\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.4365 - val_loss: 0.5813\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4080 - val_loss: 0.3788\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.4348 - val_loss: 0.3470\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.3750 - val_loss: 0.4384\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2232 - val_loss: 0.2241\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2137 - val_loss: 0.2226\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2116 - val_loss: 0.2204\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2113 - val_loss: 0.2194\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2106 - val_loss: 0.2199\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2104 - val_loss: 0.2363\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2116 - val_loss: 0.2200\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2112 - val_loss: 0.2350\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2105 - val_loss: 0.2199\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2104 - val_loss: 0.2194\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2097 - val_loss: 0.2181\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2092 - val_loss: 0.2166\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2097 - val_loss: 0.2206\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2116 - val_loss: 0.2174\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2099 - val_loss: 0.2164\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2093 - val_loss: 0.2214\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2094 - val_loss: 0.2176\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2107 - val_loss: 0.2236\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2092 - val_loss: 0.2186\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2128 - val_loss: 0.2256\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2152 - val_loss: 0.2276\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2165 - val_loss: 0.2230\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.2049 - val_loss: 0.2159\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2042 - val_loss: 0.2161\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2035 - val_loss: 0.2167\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2039 - val_loss: 0.2148\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2034 - val_loss: 0.2153\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2035 - val_loss: 0.2165\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2033 - val_loss: 0.2156\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2030 - val_loss: 0.2159\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2030 - val_loss: 0.2147\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2032 - val_loss: 0.2157\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2037 - val_loss: 0.2151\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2015 - val_loss: 0.2156\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2013 - val_loss: 0.2150\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2012 - val_loss: 0.2154\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2011 - val_loss: 0.2154\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.2011 - val_loss: 0.2153\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2011 - val_loss: 0.2156\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2010 - val_loss: 0.2153\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2006 - val_loss: 0.2153\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2006 - val_loss: 0.2152\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2006 - val_loss: 0.2152\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2006 - val_loss: 0.2152\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2006 - val_loss: 0.2153\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2006 - val_loss: 0.2156\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2006 - val_loss: 0.2156\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2005 - val_loss: 0.2153\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2004 - val_loss: 0.2153\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2004 - val_loss: 0.2153\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2005 - val_loss: 0.2153\n",
      "Fold 4 NN: 0.21474\n",
      "CV 5/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 10.6271 - val_loss: 1.4535\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.8322 - val_loss: 0.6260\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6075 - val_loss: 0.3039\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3440 - val_loss: 0.9289\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.6375 - val_loss: 0.6089\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.5837 - val_loss: 0.5336\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.6808 - val_loss: 0.4546\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.4894 - val_loss: 0.3744\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4512 - val_loss: 0.4412\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.4693 - val_loss: 0.4466\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2266 - val_loss: 0.2354\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2148 - val_loss: 0.2201\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2133 - val_loss: 0.2193\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2134 - val_loss: 0.2203\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2130 - val_loss: 0.2273\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2132 - val_loss: 0.2193\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2119 - val_loss: 0.2205\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2108 - val_loss: 0.2183\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2121 - val_loss: 0.2312\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2145 - val_loss: 0.2281\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2128 - val_loss: 0.2297\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2113 - val_loss: 0.2208\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2113 - val_loss: 0.2197\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2108 - val_loss: 0.2268\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2156 - val_loss: 0.2249\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2065 - val_loss: 0.2163\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.2055 - val_loss: 0.2150\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2054 - val_loss: 0.2166\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2052 - val_loss: 0.2158\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2054 - val_loss: 0.2172\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2057 - val_loss: 0.2176\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2054 - val_loss: 0.2163\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2055 - val_loss: 0.2156\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2061 - val_loss: 0.2164\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2040 - val_loss: 0.2157\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2038 - val_loss: 0.2152\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2037 - val_loss: 0.2156\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2037 - val_loss: 0.2158\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2037 - val_loss: 0.2154\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2037 - val_loss: 0.2157\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2038 - val_loss: 0.2156\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.2033 - val_loss: 0.2150\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2032 - val_loss: 0.2151\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2032 - val_loss: 0.2152\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2032 - val_loss: 0.2152\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2032 - val_loss: 0.2152\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.2032 - val_loss: 0.2151\n",
      "Fold 5 NN: 0.21496\n"
     ]
    }
   ],
   "source": [
    "target_name='target'\n",
    "scores_folds = {}\n",
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "n_folds = 5\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2020)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = list(train_nn)\n",
    "\n",
    "features_to_consider.remove('time_id')\n",
    "features_to_consider.remove('target')\n",
    "try:\n",
    "    features_to_consider.remove('pred_NN')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "train_nn[features_to_consider] = train_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "test_nn[features_to_consider] = test_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "\n",
    "train_nn[pred_name] = 0\n",
    "test_nn[target_name] = 0\n",
    "test_predictions_nn = np.zeros(test_nn.shape[0])\n",
    "\n",
    "for n_count in range(n_folds):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    indexes = np.arange(nfolds).astype(int)    \n",
    "    indexes = np.delete(indexes,obj=n_count, axis=0) \n",
    "    \n",
    "    indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n",
    "    \n",
    "    X_train = train_nn.loc[train_nn.time_id.isin(indexes), features_to_consider]\n",
    "    y_train = train_nn.loc[train_nn.time_id.isin(indexes), target_name]\n",
    "    X_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), features_to_consider]\n",
    "    y_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), target_name]\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    \n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.006),\n",
    "        loss=root_mean_squared_per_error\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        features_to_consider.remove('stock_id')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_data = X_train[features_to_consider]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))         \n",
    "    num_data = scaler.fit_transform(num_data.values)    \n",
    "    \n",
    "    cat_data = X_train['stock_id']    \n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[features_to_consider]\n",
    "    num_data_test = scaler.transform(num_data_test.values)\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target,               \n",
    "              batch_size=2048,\n",
    "              epochs=1000,\n",
    "              validation_data=([cat_data_test, num_data_test], y_test),\n",
    "              callbacks=[es, plateau],\n",
    "              validation_batch_size=len(y_test),\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    \n",
    "    tt =scaler.transform(test_nn[features_to_consider].values)\n",
    "    #test_nn[target_name] += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)\n",
    "    test_predictions_nn += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)/n_folds\n",
    "    #test[target_name] += model.predict([test['stock_id'], test[features_to_consider]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "    counter += 1\n",
    "    features_to_consider.append('stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f8bb0aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T07:00:02.753602Z",
     "iopub.status.busy": "2022-01-25T07:00:02.752874Z",
     "iopub.status.idle": "2022-01-25T07:00:02.773220Z",
     "shell.execute_reply": "2022-01-25T07:00:02.773880Z",
     "shell.execute_reply.started": "2021-08-30T10:06:01.102575Z"
    },
    "papermill": {
     "duration": 3.70682,
     "end_time": "2022-01-25T07:00:02.774056",
     "exception": false,
     "start_time": "2022-01-25T06:59:59.067236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE NN: 1.0 - Folds: [0.20941, 0.21151, 0.20894, 0.21474, 0.21496]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.002510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-32</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-34</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.002510\n",
       "1   0-32  0.002168\n",
       "2   0-34  0.002168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_nn[\"row_id\"] = test_nn[\"stock_id\"].astype(str) + \"-\" + test_nn[\"time_id\"].astype(str)\n",
    "pred_lgb_m = predictions_lgb*0.615+predictions_lgb2*0.385\n",
    "test_nn[target_name] = test_predictions_nn*0.585 + pred_lgb_m*0.415\n",
    "\n",
    "score = round(rmspe(y_true = train_nn[target_name].values, y_pred = train_nn[pred_name].values),5)\n",
    "print('RMSPE {}: {} - Folds: {}'.format(model_name, score, scores_folds[model_name]))\n",
    "\n",
    "display(test_nn[['row_id', target_name]].head(3))\n",
    "test_nn[['row_id', target_name]].to_csv('submission.csv',index = False)\n",
    "#test[['row_id', target_name]].to_csv('submission.csv',index = False)\n",
    "#kmeans N=5 [0.2101, 0.21399, 0.20923, 0.21398, 0.21175]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6187.473598,
   "end_time": "2022-01-25T07:00:09.686648",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-25T05:17:02.213050",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
